{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View all datasets:\n",
      "disc_df.csv\n",
      "bda2024_202203-202402_討論數據_dcard.csv\n",
      ".DS_Store\n",
      "bda2024_202203-202402_內容數據_新聞3-8.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-9.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-9.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-8.csv\n",
      "bda2024_微股力_社群PKTD-2年-3.csv\n",
      "bda2024_微股力_籌碼數據-2年.csv\n",
      "bda2024_微股力_社群PKTD-2年-2.csv\n",
      "bda2024_微股力_社群PKTD-2年-0.csv\n",
      "bda2024_微股力_社群PKTD-2年-1.csv\n",
      "bda2024_微股力_社群PKTD-2年-5.csv\n",
      "bda2024_202203-202402_討論數據_ptt.csv\n",
      "bda2024_微股力_社群PKTD-2年-4.csv\n",
      "bda2024_微股力_社群PKTD-2年-6.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-8.csv\n",
      "bda2024_微股力_財報數據-2年.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-9.csv\n",
      "bda2024_微股力_社群PKTD-2年-7.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-4.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-5.csv\n",
      "bda2024_微股力_社群PKTD-2年-9.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-7.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-6.csv\n",
      "bda2024_微股力_社群PKTD-2年-8.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-2.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-3.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-1.csv\n",
      "bda2024_微股力_個股交易數據-2年.csv\n",
      "bda2024_202203-202402_內容數據_新聞2-0.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-5.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-7.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-6.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-4.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-6.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-4.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-5.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-7.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-3.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-1.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-0.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-2.csv\n",
      "bda2024_202203-202402_討論數據_mobile01-1.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-0.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-2.csv\n",
      "bda2024_202203-202402_內容數據_新聞3-3.csv\n",
      "bda2024_202203-202402_內容數據_新聞1-1.csv\n",
      "bda2024_202203-202402_討論數據_mobile01-2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/CV2023/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "data_dir = \"./dataset\"\n",
    "%cd -q dataset\n",
    "\n",
    "files = os.listdir()\n",
    "print(\"View all datasets:\")\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filepath, preview=True):\n",
    "    print(f\"\\n----- Loading {filepath}... -----\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Size of dataframe: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if preview:\n",
    "        print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為要討論 ppt / 各種論壇的情緒指標和討論聲量和產業的關係，因此沒有用新聞內容的 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Loading bda2024_202203-202402_討論數據_dcard.csv... -----\n",
      "Size of dataframe: (231320, 10)\n",
      "Columns: ['id', 'forum', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading bda2024_202203-202402_討論數據_mobile01-1.csv... -----\n",
      "Size of dataframe: (48725, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading bda2024_202203-202402_討論數據_mobile01-2.csv... -----\n",
      "Size of dataframe: (157939, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading bda2024_202203-202402_討論數據_ptt.csv... -----\n",
      "Size of dataframe: (50805, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n",
      "\n",
      "----- Loading bda2024_微股力_個股交易數據-2年.csv... -----\n",
      "Size of dataframe: (1154225, 8)\n",
      "Columns: ['stock_name', 'stock_symbol', 'open', 'high', 'low', 'close', 'volume', 'date']\n",
      "  stock_name stock_symbol   open   high    low  close  volume  \\\n",
      "0         日馳         1526  47.55  48.45  47.55  48.30     138   \n",
      "1         日馳         1526  48.30  48.30  47.40  47.95     153   \n",
      "2         日馳         1526  48.45  48.70  47.80  48.10     120   \n",
      "3         日馳         1526  47.95  47.95  47.55  47.60     165   \n",
      "4         日馳         1526  47.65  47.65  45.30  45.65     514   \n",
      "\n",
      "                  date  \n",
      "0  2022-03-01 00:00:00  \n",
      "1  2022-03-02 00:00:00  \n",
      "2  2022-03-03 00:00:00  \n",
      "3  2022-03-04 00:00:00  \n",
      "4  2022-03-07 00:00:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/rxqxvrmd0z1bnnny3trbtfz80000gn/T/ipykernel_36421/550884886.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "disc_dcard_df = load_df(\"bda2024_202203-202402_討論數據_dcard.csv\", preview=False)\n",
    "disc_dcard_df.rename(columns={'forum': 'p_type'}, inplace=True)    # Repair column name typo in data\n",
    "disc_m1_df = load_df(\"bda2024_202203-202402_討論數據_mobile01-1.csv\", preview=False)\n",
    "disc_m2_df = load_df(\"bda2024_202203-202402_討論數據_mobile01-2.csv\", preview=False)\n",
    "disc_ptt_df = load_df(\"bda2024_202203-202402_討論數據_ptt.csv\", preview=False)\n",
    "disc_df = pd.concat([disc_dcard_df, disc_m1_df, disc_m2_df, disc_ptt_df], ignore_index=True)\n",
    "\n",
    "transaction_df = load_df(\"bda2024_微股力_個股交易數據-2年.csv\")\n",
    "\n",
    "transaction_df['stock_symbol'] = transaction_df['stock_symbol'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_df = disc_df[[\"id\", \"post_time\", \"content\"]]\n",
    "\n",
    "disc_df[\"content\"] = disc_df[\"content\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 股價漲跌 Labeling\n",
    "\n",
    "AI 概念股：\n",
    "\n",
    "https://www.sinotrade.com.tw/richclub/hotstock/-65af4cb1880d9e29902a677f\n",
    "\n",
    "https://www.wantgoo.com/index/%5E435/stocks\n",
    "\n",
    "\n",
    "利用「全部 AI 概念股 n 天後的股價」減掉「全部 AI 概念股今天的股價」來當作判斷，若漲幅超過 m% 則判斷為漲。\n",
    "\n",
    "n = 7, m = 5 (暫定)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target stocks\n",
    "\n",
    "target_stock_name_1 = ['廣達', '緯創', '台積電', '創意', '世芯-KY', '智原', '智邦', '信驊', '譜瑞-KY', '日月光投控', '台達電', '光寶科', '群光', '奇鋐', '金像電', '台燿', '嘉澤', '技嘉', '緯穎', '英業達', '鴻海', '聯發科', '聯茂', 'M31']\n",
    "target_stock_name_2 = ['AMAX-KY','緯創','凌群','創意','東元','英業達','原相','長佳智能','精誠','鴻海','華碩','微星','金寶','聯發科','世芯-KY','京元電子','美律','亞信','研華','台積電','宏碁','走著瞧-創','鈺創','廣達','凌華','零壹','台達電','樺漢','群電']\n",
    "\n",
    "#get rid of the duplicate stock names\n",
    "target_stock_name = target_stock_name_1 + target_stock_name_2\n",
    "target_stock_name = list(set(target_stock_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df['date'] = pd.to_datetime(transaction_df['date']).dt.date\n",
    "disc_df['post_time'] = pd.to_datetime(disc_df['post_time'])\n",
    "disc_df['post_time'] = disc_df['post_time'].dt.date\n",
    "\n",
    "#add a column \"rise\" in transaction_df to indicate whether the stock price rises or not, default is null\n",
    "disc_df[\"rise\"] = np.nan\n",
    "\n",
    "dates_list = sorted(list(set(transaction_df[\"date\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the sum of the stock price in stock_name n days later is higher than the sum of stock price today by more than 5%, then label today's disc_df[\"rise\"] as 1\n",
    "# if the sum of the stock price in stock_name n days later is lower than the sum of stock price today by more than 5%, then label today's disc_df[\"rise\"] as -1\n",
    "# if the sum of the stock price in stock_name n days later is within 5% of the sum of stock price today, then label today's disc_df[\"rise\"] as 0\n",
    "\n",
    "n = 7\n",
    "m = 0.05\n",
    "\n",
    "for i in range(len(dates_list[:-7])):\n",
    "    #check the availability of stock price data of stock_name today\n",
    "    stock_data_today = transaction_df[transaction_df[\"date\"] == dates_list[i]]\n",
    "    stock_data_today_name = stock_data_today[\"stock_name\"].values\n",
    "\n",
    "    #check the availability of stock price data of stock_name n days later\n",
    "    stock_data_later = transaction_df[transaction_df[\"date\"] == dates_list[i + n]]\n",
    "    stock_data_later_name = stock_data_later[\"stock_name\"].values\n",
    "\n",
    "    #get the available stocks on both today and later\n",
    "    stock_name = [stock for stock in stock_data_today_name if stock in stock_data_later_name]\n",
    "\n",
    "    stock_name = [stock for stock in stock_name if stock in target_stock_name]\n",
    "    \n",
    "    if len(stock_name) == 0:\n",
    "        continue\n",
    "\n",
    "    #if stock_name is not available in stock data, then label today's disc_df[\"rise\"] as -100\n",
    "\n",
    "    #calculate the sum of stock price of stock_name today\n",
    "    stock_price_today = 0\n",
    "    for stock in stock_name:\n",
    "        if stock in stock_data_today_name:\n",
    "            stock_price_today += stock_data_today[stock_data_today[\"stock_name\"] == stock][\"open\"].values[0]\n",
    "\n",
    "    #calculate the sum of stock price of stock_name n days later\n",
    "    stock_price_later = 0\n",
    "    for stock in stock_name:\n",
    "        if stock in stock_data_later_name:\n",
    "            stock_price_later += stock_data_later[stock_data_later[\"stock_name\"] == stock][\"close\"].values[0]\n",
    "\n",
    "    #calculate the percentage change of stock price, and label the data in disc_df[\"rise\"]\n",
    "    percentage_change = (stock_price_later - stock_price_today) / stock_price_today\n",
    "    if percentage_change > m:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"rise\"] = 1\n",
    "    elif percentage_change < -m:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"rise\"] = -1\n",
    "    else:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"rise\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the data with disc_df[\"rise\"] == null\n",
    "disc_df = disc_df[disc_df[\"rise\"].notnull()]\n",
    "# get rid of the data with disc_df[\"rise\"] == 0\n",
    "disc_df = disc_df[disc_df[\"rise\"] != 0]\n",
    "\n",
    "# reassign the post_id\n",
    "disc_df[\"post_id\"] = range(len(disc_df))\n",
    "\n",
    "#export disc_df to csv\n",
    "disc_df.to_csv(\"disc_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找出具鑑別力 (扣除共通字詞) 的關鍵字列表，合起來建構向量空間\n",
    "\n",
    "1000維度（？），把所有資料轉換成以這個向量空間為主的向量（嗎）\n",
    "\n",
    "先取 5000 筆當作 training data 來建構具鑑別力 (扣除共通字詞) 的關 鍵字列表，合起來建構向量空間\n",
    "1000 筆當作 testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (5000, 5)\n",
      "Testing data shape: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# get 5000 of the data as training data\n",
    "# get 1000 of the data as testing data\n",
    "\n",
    "train_data, test_data = train_test_split(disc_df, train_size=5000, test_size=1000, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 monpa 切(因為 CkipTagger 要 tensorflow 1.13， 但那要 python 3.8 垃圾)\n",
    "\n",
    "(還是用 jieba 比較好？)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------+\n",
      "  Welcome to MONPA: Multi-Objective NER POS Annotator for Chinese\n",
      "+---------------------------------------------------------------------+\n",
      "已找到 model檔。Found model file.\n"
     ]
    }
   ],
   "source": [
    "# use monpa to segment the content\n",
    "\n",
    "# add a new column \"segmented_content\" to store the segmented content\n",
    "train_data[\"segmented_content\"] = np.nan\n",
    "test_data[\"segmented_content\"] = np.nan\n",
    "\n",
    "tmp = []\n",
    "\n",
    "import monpa\n",
    "for i in range(len(train_data)):\n",
    "    segmented_content = monpa.cut(train_data[\"content\"].iloc[i])\n",
    "    tmp.append(segmented_content)\n",
    "\n",
    "train_data[\"segmented_content\"] = tmp\n",
    "\n",
    "tmp = []\n",
    "\n",
    "import monpa\n",
    "for i in range(len(test_data)):\n",
    "    segmented_content = monpa.cut(test_data[\"content\"].iloc[i])\n",
    "    tmp.append(segmented_content)\n",
    "\n",
    "test_data[\"segmented_content\"] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export train_data and test_data to csv\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# # use all the text in the training data to build a dictionary\n",
    "# dictionary = []\n",
    "# for i in range(len(train_data)):\n",
    "#     dictionary += train_data[\"segmented_content\"].iloc[i]\n",
    "\n",
    "# dictionary = list(set(dictionary))\n",
    "\n",
    "# print(\"The size of the dictionary is:\", len(dictionary))\n",
    "\n",
    "# # for each data in training data, count the frequency of each word in the dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
