{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024BDA - Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View all datasets:\n",
      "['disc_df.csv', 'bda2024_202203-202402_è¨è«–æ•¸æ“š_dcard.csv', '.DS_Store', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-8.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-9.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-9.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-8.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-3.csv', 'bda2024_å¾®è‚¡åŠ›_ç±Œç¢¼æ•¸æ“š-2å¹´.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-2.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-0.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-1.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-5.csv', 'bda2024_202203-202402_è¨è«–æ•¸æ“š_ptt.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-4.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-6.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-8.csv', 'bda2024_å¾®è‚¡åŠ›_è²¡å ±æ•¸æ“š-2å¹´.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-9.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-7.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-4.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-5.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-9.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-7.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-6.csv', 'bda2024_å¾®è‚¡åŠ›_ç¤¾ç¾¤PKTD-2å¹´-8.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-2.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-3.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-1.csv', 'bda2024_å¾®è‚¡åŠ›_å€‹è‚¡äº¤æ˜“æ•¸æ“š-2å¹´.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è2-0.csv', 'train_data.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-5.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-7.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-6.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-4.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-6.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-4.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-5.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-7.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-3.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-1.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-0.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-2.csv', 'bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-1.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-0.csv', 'test_data.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-2.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è3-3.csv', 'bda2024_202203-202402_å…§å®¹æ•¸æ“š_æ–°è1-1.csv', 'bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-2.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset_dir = \"./dataset\"\n",
    "\n",
    "files = [f for f in os.listdir(dataset_dir) if os.path.isfile(os.path.join(dataset_dir, f))]\n",
    "print(\"View all datasets:\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filepath, preview=True):\n",
    "    print(f\"\\n----- Loading {filepath}... -----\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Size of dataframe: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if preview:\n",
    "        print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ç‚ºè¦è¨è«– ppt / å„ç¨®è«–å£‡çš„æƒ…ç·’æŒ‡æ¨™å’Œè¨è«–è²é‡å’Œç”¢æ¥­çš„é—œä¿‚ï¼Œå› æ­¤æ²’æœ‰ç”¨æ–°èå…§å®¹çš„ data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Loading ./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_dcard.csv... -----\n",
      "Size of dataframe: (231320, 10)\n",
      "Columns: ['id', 'forum', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-1.csv... -----\n",
      "Size of dataframe: (48725, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-2.csv... -----\n",
      "Size of dataframe: (157939, 10)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url', 'content_type']\n",
      "\n",
      "----- Loading ./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_ptt.csv... -----\n",
      "Size of dataframe: (50805, 9)\n",
      "Columns: ['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author', 'content', 'page_url']\n",
      "\n",
      "----- Loading ./dataset/bda2024_å¾®è‚¡åŠ›_å€‹è‚¡äº¤æ˜“æ•¸æ“š-2å¹´.csv... -----\n",
      "Size of dataframe: (1154225, 8)\n",
      "Columns: ['stock_name', 'stock_symbol', 'open', 'high', 'low', 'close', 'volume', 'date']\n",
      "  stock_name stock_symbol   open   high    low  close  volume  \\\n",
      "0         æ—¥é¦³         1526  47.55  48.45  47.55  48.30     138   \n",
      "1         æ—¥é¦³         1526  48.30  48.30  47.40  47.95     153   \n",
      "2         æ—¥é¦³         1526  48.45  48.70  47.80  48.10     120   \n",
      "3         æ—¥é¦³         1526  47.95  47.95  47.55  47.60     165   \n",
      "4         æ—¥é¦³         1526  47.65  47.65  45.30  45.65     514   \n",
      "\n",
      "                  date  \n",
      "0  2022-03-01 00:00:00  \n",
      "1  2022-03-02 00:00:00  \n",
      "2  2022-03-03 00:00:00  \n",
      "3  2022-03-04 00:00:00  \n",
      "4  2022-03-07 00:00:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/rxqxvrmd0z1bnnny3trbtfz80000gn/T/ipykernel_30216/550884886.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "disc_dcard_df = load_df(\"./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_dcard.csv\", preview=False)\n",
    "disc_dcard_df.rename(columns={'forum': 'p_type'}, inplace=True)    # Repair column name typo in data\n",
    "disc_m1_df = load_df(\"./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-1.csv\", preview=False)\n",
    "disc_m2_df = load_df(\"./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_mobile01-2.csv\", preview=False)\n",
    "disc_ptt_df = load_df(\"./dataset/bda2024_202203-202402_è¨è«–æ•¸æ“š_ptt.csv\", preview=False)\n",
    "disc_df = pd.concat([disc_dcard_df, disc_m1_df, disc_m2_df, disc_ptt_df], ignore_index=True)\n",
    "\n",
    "transaction_df = load_df(\"./dataset/bda2024_å¾®è‚¡åŠ›_å€‹è‚¡äº¤æ˜“æ•¸æ“š-2å¹´.csv\")\n",
    "\n",
    "transaction_df['stock_symbol'] = transaction_df['stock_symbol'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_df = disc_df[[\"id\", \"post_time\", \"content\"]]\n",
    "\n",
    "disc_df[\"content\"] = disc_df[\"content\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Labeling\n",
    "\n",
    "AI æ¦‚å¿µè‚¡ï¼š\n",
    "\n",
    "https://www.sinotrade.com.tw/richclub/hotstock/-65af4cb1880d9e29902a677f\n",
    "\n",
    "https://www.wantgoo.com/index/%5E435/stocks\n",
    "\n",
    "\n",
    "åˆ©ç”¨ã€Œå…¨éƒ¨ AI æ¦‚å¿µè‚¡ n å¤©å¾Œçš„è‚¡åƒ¹ã€æ¸›æ‰ã€Œå…¨éƒ¨ AI æ¦‚å¿µè‚¡ä»Šå¤©çš„è‚¡åƒ¹ã€ä¾†ç•¶ä½œåˆ¤æ–·ï¼Œè‹¥æ¼²å¹…è¶…é m% å‰‡åˆ¤æ–·ç‚ºæ¼²ã€‚\n",
    "\n",
    "n = 7, m = 5 (æš«å®š)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target stocks\n",
    "\n",
    "target_stock_name_1 = ['å»£é”', 'ç·¯å‰µ', 'å°ç©é›»', 'å‰µæ„', 'ä¸–èŠ¯-KY', 'æ™ºåŸ', 'æ™ºé‚¦', 'ä¿¡é©Š', 'è­œç‘-KY', 'æ—¥æœˆå…‰æŠ•æ§', 'å°é”é›»', 'å…‰å¯¶ç§‘', 'ç¾¤å…‰', 'å¥‡é‹', 'é‡‘åƒé›»', 'å°ç‡¿', 'å˜‰æ¾¤', 'æŠ€å˜‰', 'ç·¯ç©', 'è‹±æ¥­é”', 'é´»æµ·', 'è¯ç™¼ç§‘', 'è¯èŒ‚', 'M31']\n",
    "target_stock_name_2 = ['AMAX-KY','ç·¯å‰µ','å‡Œç¾¤','å‰µæ„','æ±å…ƒ','è‹±æ¥­é”','åŸç›¸','é•·ä½³æ™ºèƒ½','ç²¾èª ','é´»æµ·','è¯ç¢©','å¾®æ˜Ÿ','é‡‘å¯¶','è¯ç™¼ç§‘','ä¸–èŠ¯-KY','äº¬å…ƒé›»å­','ç¾å¾‹','äºä¿¡','ç ”è¯','å°ç©é›»','å®ç¢','èµ°è‘—ç§-å‰µ','éˆºå‰µ','å»£é”','å‡Œè¯','é›¶å£¹','å°é”é›»','æ¨ºæ¼¢','ç¾¤é›»']\n",
    "\n",
    "#get rid of the duplicate stock names\n",
    "target_stock_name = target_stock_name_1 + target_stock_name_2\n",
    "target_stock_name = list(set(target_stock_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646109801927_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646109801940_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646115341451_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æˆ‘ä¸‰ç™¾è²·çš„ çµ¦ä½ åƒè€ƒ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1646113689192_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>ä¸­é‹¼å‘¢</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646068286032_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰\\nç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   post_time                             content  label\n",
       "0  1646109801927_F0DCU  2022-03-01            å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼    NaN\n",
       "1  1646109801940_F0DCU  2022-03-01                  æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿    NaN\n",
       "2  1646115341451_F0DCU  2022-03-01                          æˆ‘ä¸‰ç™¾è²·çš„ çµ¦ä½ åƒè€ƒ    NaN\n",
       "3  1646113689192_F0DCU  2022-03-01                                 ä¸­é‹¼å‘¢    NaN\n",
       "4  1646068286032_F0DCU  2022-03-01  æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰\\nç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df['date'] = pd.to_datetime(transaction_df['date']).dt.date\n",
    "disc_df['post_time'] = pd.to_datetime(disc_df['post_time'])\n",
    "disc_df['post_time'] = disc_df['post_time'].dt.date\n",
    "\n",
    "#add a column \"label\" in transaction_df to indicate whether the stock price rises or not, default is null\n",
    "disc_df[\"label\"] = np.nan\n",
    "\n",
    "dates_list = sorted(list(set(transaction_df[\"date\"])))\n",
    "disc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the sum of the stock price in stock_name n days later is higher than the sum of stock price today by more than 5%, then label today's disc_df[\"rise\"] as 1\n",
    "# if the sum of the stock price in stock_name n days later is lower than the sum of stock price today by more than 5%, then label today's disc_df[\"rise\"] as -1\n",
    "# if the sum of the stock price in stock_name n days later is within 5% of the sum of stock price today, then label today's disc_df[\"rise\"] as 0\n",
    "\n",
    "n = 7\n",
    "m = 0.05\n",
    "\n",
    "for i in range(len(dates_list[:-7])):\n",
    "    #check the availability of stock price data of stock_name today\n",
    "    stock_data_today = transaction_df[transaction_df[\"date\"] == dates_list[i]]\n",
    "    stock_data_today_name = stock_data_today[\"stock_name\"].values\n",
    "\n",
    "    #check the availability of stock price data of stock_name n days later\n",
    "    stock_data_later = transaction_df[transaction_df[\"date\"] == dates_list[i + n]]\n",
    "    stock_data_later_name = stock_data_later[\"stock_name\"].values\n",
    "\n",
    "    #get the available stocks on both today and later\n",
    "    stock_name = [stock for stock in stock_data_today_name if stock in stock_data_later_name]\n",
    "\n",
    "    stock_name = [stock for stock in stock_name if stock in target_stock_name]\n",
    "    \n",
    "    if len(stock_name) == 0:\n",
    "        continue\n",
    "\n",
    "    #if stock_name is not available in stock data, then label today's disc_df[\"rise\"] as -100\n",
    "\n",
    "#     #calculate the sum of stock price of stock_name today\n",
    "#     stock_price_today = 0\n",
    "#     for stock in stock_name:\n",
    "#         if stock in stock_data_today_name:\n",
    "#             stock_price_today += stock_data_today[stock_data_today[\"stock_name\"] == stock][\"open\"].values[0]\n",
    "\n",
    "#     #calculate the sum of stock price of stock_name n days later\n",
    "#     stock_price_later = 0\n",
    "#     for stock in stock_name:\n",
    "#         if stock in stock_data_later_name:\n",
    "#             stock_price_later += stock_data_later[stock_data_later[\"stock_name\"] == stock][\"close\"].values[0]\n",
    "\n",
    "#     #calculate the percentage change of stock price, and label the data in disc_df[\"rise\"]\n",
    "#     percentage_change = (stock_price_later - stock_price_today) / stock_price_today\n",
    "\n",
    "    \n",
    "    #calculate the sum of stock price of stock_name today\n",
    "    \n",
    "    percentage_change_sum = 0\n",
    "    \n",
    "    for stock in stock_name:\n",
    "        if stock in stock_data_today_name and stock in stock_data_later_name:\n",
    "            tmp = stock_data_later[stock_data_later[\"stock_name\"] == stock][\"close\"].values[0]-stock_data_today[stock_data_today[\"stock_name\"] == stock][\"open\"].values[0]\n",
    "            tmp = tmp/stock_data_today[stock_data_today[\"stock_name\"] == stock][\"open\"].values[0]\n",
    "            percentage_change_sum += tmp\n",
    "\n",
    "#     #calculate the percentage change of stock price, and label the data in disc_df[\"rise\"]\n",
    "#     percentage_change = (stock_price_later - stock_price_today) / stock_price_today\n",
    "    \n",
    "    percentage_change = percentage_change_sum/len(stock_name)\n",
    "    \n",
    "    if percentage_change > m:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"label\"] = 1\n",
    "    elif percentage_change < -m:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"label\"] = -1\n",
    "    else:\n",
    "        disc_df.loc[disc_df[\"post_time\"] == dates_list[i], \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the data with disc_df[\"rise\"] == null\n",
    "disc_df = disc_df[disc_df[\"label\"].notnull()]\n",
    "\n",
    "# reassign the post_id\n",
    "disc_df[\"post_id\"] = range(len(disc_df))\n",
    "\n",
    "#export disc_df to csv\n",
    "disc_df.to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document feature extraction\n",
    "æ‰¾å‡ºå…·é‘‘åˆ¥åŠ› (æ‰£é™¤å…±é€šå­—è©) çš„é—œéµå­—åˆ—è¡¨ï¼Œåˆèµ·ä¾†å»ºæ§‹å‘é‡ç©ºé–“\n",
    "\n",
    "1000ç¶­åº¦ï¼ˆï¼Ÿï¼‰ï¼ŒæŠŠæ‰€æœ‰è³‡æ–™è½‰æ›æˆä»¥é€™å€‹å‘é‡ç©ºé–“ç‚ºä¸»çš„å‘é‡ï¼ˆå—ï¼‰\n",
    "\n",
    "å…ˆå– 5000 ç­†ç•¶ä½œ training data ä¾†å»ºæ§‹å…·é‘‘åˆ¥åŠ› (æ‰£é™¤å…±é€šå­—è©) çš„é—œ éµå­—åˆ—è¡¨ï¼Œåˆèµ·ä¾†å»ºæ§‹å‘é‡ç©ºé–“\n",
    "1000 ç­†ç•¶ä½œ testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "æŠŠæ–‡ç« å…§çš„ç©ºç™½ã€å¥‡æ€ªçš„å­—å…ƒå»æ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text(document: str):\n",
    "    # remove html tags\n",
    "    CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    clean_document = re.sub(CLEANR, '', document)\n",
    "    clean_document = re.sub(\n",
    "        r'^https?:\\/\\/.*[\\r\\n]*', '', clean_document, flags=re.MULTILINE)  # remove urls\n",
    "    clean_document = re.sub(r\"\\s+\", \"\", clean_document,\n",
    "                            flags=re.UNICODE)  # remove white spaces\n",
    "    clean_document = clean_document.replace(\"\\n\", \"\") .replace(\"\\r\\n\", \"\")\n",
    "    # remove line terminator\n",
    "    clean_document = re.sub(r\"/[^\\x20-\\x7E]/gmi\", \"\", clean_document)\n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    clean_document = re.sub(emoji_pattern, \"\", clean_document)\n",
    "    return clean_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646109801927_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646109801940_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646115341451_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æˆ‘ä¸‰ç™¾è²·çš„çµ¦ä½ åƒè€ƒ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1646113689192_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>ä¸­é‹¼å‘¢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646068286032_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰ç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   post_time                           content  label  \\\n",
       "0  1646109801927_F0DCU  2022-03-01          å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼    0.0   \n",
       "1  1646109801940_F0DCU  2022-03-01                æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿    0.0   \n",
       "2  1646115341451_F0DCU  2022-03-01                         æˆ‘ä¸‰ç™¾è²·çš„çµ¦ä½ åƒè€ƒ    0.0   \n",
       "3  1646113689192_F0DCU  2022-03-01                               ä¸­é‹¼å‘¢    0.0   \n",
       "4  1646068286032_F0DCU  2022-03-01  æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰ç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ    0.0   \n",
       "\n",
       "   post_id  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"./dataset.csv\")\n",
    "dataset[\"content\"] = dataset[\"content\"].astype(str)\n",
    "dataset[\"content\"] = dataset[\"content\"].apply(lambda x : clean_text(x))\n",
    "dataset.to_csv(\"./clean_dataset.csv\", index=False)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/369694 [00:00<?, ?it/s]/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['[', ']', 'a', 'ä¸€é»', 'ä¸‹', 'ä¸‹å»', 'ä¸å¯', 'ä¸æ–·', 'ä¸»ç¾©', 'ä¹‹é–“', 'äºŒè©±', 'äº›', 'äº¦', 'äº®è©±', 'äººæ„', 'ä»Š', 'ä»¤', 'ä»¥ä¾†', 'ä»¥å¤–', 'ä»¥å¾Œ', 'ä½', 'ä½•æ¨‚', 'ä½¿', 'ä¾‹å¤–', 'ä¿ç•™', 'å€’', 'å‡', 'å¶', 'å……', 'å…’', 'å…¨', 'å…©', 'å…·é«”', 'å†', 'å‡¡', 'åˆ†æ‰¹', 'åˆ»', 'åˆ»é–“', 'å‰', 'åŠ ', 'å‹¿', 'å»', 'å£å…’', 'å¤', 'åª', 'å®', 'å‘†å‘†', 'å‘¼', 'å”·', 'å•', 'å•ª', 'å–”', 'å™ ', 'åš´', 'å¤–', 'å¤ ', 'å¤§å¼µ', 'å¤§é¢å…’', 'å¤©', 'å¤©çª—', 'å¥½', 'å°‘', 'å·§', 'å·®', 'å·²', 'å¹´', 'å¹´è¦†', 'åº¦', 'å¼', 'å½ˆæŒ‡', 'å¾—åŠ', 'å¿½', 'æ°', 'æƒ…', 'æ…¢', 'æ…£', 'æˆ', 'æˆ–å°‘', 'æ‰‹æ®µ', 'æ‰“é–‹', 'æŠ—æ‹’', 'æŠµ', 'æŒ¨', 'æŒ¨å®¶', 'æŒ¨æˆ¶', 'æŒ¨é–€', 'æ¥é€£', 'æ›å¥', 'æ“‡', 'æ•é–‹', 'æ–°', 'æ——é¼“', 'æ—¥', 'æ—¥è¦†', 'æ—©', 'æ™‚', 'æ™š', 'æš—åœ°', 'æœƒå…’', 'æœ«', 'æ¨‚ä¹', 'æ¨£', 'æ¨£å­', 'æ¬Š', 'æ¬¡', 'æ­¢', 'æ­£', 'æ­¸æ ¹', 'æ¯åˆ»', 'æ¯æ™‚', 'æ¯«', 'æ±º', 'æ³', 'æ¶ˆ', 'ç‚ºæ­¢', 'çƒ', 'ç„¡', 'ç„¡åˆ°', 'ç„¡é˜»', 'ç†±', 'çˆ¾', 'ç‰¹', 'ç¨åš', 'ç”±æ­¤', 'ç•ª', 'çš†', 'ç›Šå–„', 'ç›¡åŠ›', 'ç›¡å¿ƒ', 'ç›®å‰', 'ç›¸å', 'ç›¸å°', 'çœŸ', 'ç§', 'çŸ¥', 'çŸ­', 'ç¤¾æœƒ', 'ç¨®', 'çª®å¹´', 'ç«­åŠ›', 'ç­–ç•¥', 'ç°¡è€Œè¨€', 'ç°¡è¨€', 'ç´¯æœˆ', 'çµåº•', 'ç¶œ', 'ç¸½', 'ç½·', 'è‚©', 'èƒŒ', 'èƒŒåœ°', 'è‡³ä»Š', 'èˆ‰', 'è‹¦', 'è—‰', 'è£', 'è¨€', 'è¨€é“', 'è¨­', 'è©±', 'èªª', 'èªªä¾†', 'è«‹', 'è«¸', 'è¬›', 'è¶Š', 'è¶•æ—©', 'è¶•æ™š', 'èº«å¿ƒ', 'è¿‘å¹´', 'è¿°', 'é€æˆ¶', 'é€Ÿ', 'é€²ä¸€æ­¥', 'é”', 'é‡', 'é•·æœŸ', 'é•·æ­¤', 'é•·è©±', 'é–‹', 'é–‹äº¤', 'é–“', 'é™', 'é›£', 'é ­', 'é¡', 'é¢¨é›¨', 'é»˜é»˜', 'é»'] not in stop_words.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369694/369694 [1:43:30<00:00, 59.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import monpa\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "# monpa.use_gpu(True)\n",
    "dataset = pd.read_csv(\"./clean_dataset.csv\")\n",
    "dataset[\"content\"] = dataset[\"content\"].fillna(\"\")\n",
    "stopwords = [line.rstrip()\n",
    "             for line in open('./stopwords.txt', encoding='utf8')]\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    use_idf=True, stop_words=stopwords, tokenizer=monpa.cut, max_features=feature_dim)\n",
    "X = vectorizer.fit_transform(tqdm(dataset[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0050</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>112å¹´</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>é ­</th>\n",
       "      <th>é¢¨éšª</th>\n",
       "      <th>é«˜</th>\n",
       "      <th>é«˜é»</th>\n",
       "      <th>é´»æµ·</th>\n",
       "      <th>é»</th>\n",
       "      <th>ï¸</th>\n",
       "      <th>ï¼</th>\n",
       "      <th>ğŸ¤£</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0050   01   03   10      100   11  111  112  112å¹´   12  ...    é ­   é¢¨éšª    é«˜  \\\n",
       "0   0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.60425  0.0  0.0  0.0   0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    é«˜é»   é´»æµ·    é»    ï¸    ï¼    ğŸ¤£  label  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector = pd.DataFrame(\n",
    "    X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "document_vector[\"label\"] = dataset[\"label\"]\n",
    "document_vector.to_csv(\"document_vector.csv\",index=False)\n",
    "document_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 0.0    277732\n",
       "-1.0     53203\n",
       " 1.0     38759\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./document_vector.csv\")\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "#df = df.drop(df[df[\"label\"] == 0].index)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369694, 500) (369694,)\n"
     ]
    }
   ],
   "source": [
    "features = df.iloc[:, :-1].to_numpy()\n",
    "labels = df.iloc[:, -1].to_numpy()\n",
    "print(features.shape , labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features[:20000], labels[:20000], test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]................*.......*\n",
      "optimization finished, #iter = 23623\n",
      "obj = -37175.372624, rho = -0.999458\n",
      "nSV = 10800, nBSV = 3207\n",
      "Total nSV = 10800\n"
     ]
    }
   ],
   "source": [
    "cls = svm.SVC(kernel='poly', gamma=0.5, C=10,verbose=True , decision_function_shape='ovo').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      1.00      0.94      1765\n",
      "         1.0       0.33      0.00      0.01       235\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.61      0.50      0.47      2000\n",
      "weighted avg       0.82      0.88      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification with Deep Learning\n",
    "\n",
    "Use yiyanghkust/finbert-tone-chinese to classify text, the model is fine-tuned with financial domain knowledge, read: [link](https://arxiv.org/abs/1908.10063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49afaf8c2aa45c6ab535875fb2be36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269a0053f30e4df599ec4f2b12de826a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da4adb52b684975bf24a29f100df8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e52c7980d944c1921756ff565b948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1aef3efdd141479874893c8ad5a416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "import numpy as np\n",
    "model_path = \"yiyanghkust/finbert-tone-chinese\"\n",
    "new_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, output_attentions=True)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "PipelineInterface = TextClassificationPipeline(\n",
    "    model=new_model, tokenizer=tokenizer, return_all_scores=True)\n",
    "label = PipelineInterface(\"æ”¹è£è»Šç‡ˆå» å·¨é§ç²¾å¯†æ–°å» å•Ÿç”¨ å®£ç¤ºä»Šå¹´èµ·é€²å¿«é€Ÿæˆé•·æœŸ\")\n",
    "\n",
    "\n",
    "def convert(nlp_result: list) -> int:\n",
    "    scores = np.array([cl[\"score\"] for cl in nlp_result[0]])\n",
    "    return (np.argmax(scores)+1) % 3-1\n",
    "\n",
    "print(convert(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_time</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1646109801927_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1646109801940_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1646115341451_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æˆ‘ä¸‰ç™¾è²·çš„çµ¦ä½ åƒè€ƒ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1646113689192_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>ä¸­é‹¼å‘¢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646068286032_F0DCU</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰ç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   post_time                           content  label  \\\n",
       "0  1646109801927_F0DCU  2022-03-01          å®šè‚¡ç¾è‚¡ETFé•·æœŸå»æŠ“å ±é…¬ä¹Ÿæ˜¯é©åˆçš„æŠ•è³‡å·¥å…·æ–¹å¼    0.0   \n",
       "1  1646109801940_F0DCU  2022-03-01                æœ€è¿‘å‰›ç”³è¾¦è¦ºå¾—å®šæœŸå®šé¡æŠ•è³‡ç¾è‚¡å¾ˆæ–¹ä¾¿    0.0   \n",
       "2  1646115341451_F0DCU  2022-03-01                         æˆ‘ä¸‰ç™¾è²·çš„çµ¦ä½ åƒè€ƒ    0.0   \n",
       "3  1646113689192_F0DCU  2022-03-01                               ä¸­é‹¼å‘¢    0.0   \n",
       "4  1646068286032_F0DCU  2022-03-01  æœ‰100æ™‚å€™æ€éº¼æ²’æœ‰é¸æ“‡æ¸›ç¢¼è½è¢‹ç‚ºå®‰ç¾åœ¨ç”¨ä»€éº¼å¿ƒæ…‹åœ¨åšç•¶æ²–å‘¢ï¼Ÿï¼Ÿ    0.0   \n",
       "\n",
       "   post_id  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "doc_df = pd.read_csv(\"./clean_dataset.csv\")\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = doc_df[\"content\"].to_list()\n",
    "labels = df.iloc[:, -1].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    contents[:20000], labels[:20000], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pred = [convert(PipelineInterface(str(X_test[i]), padding=True,\n",
    "                                      truncation=True)) for i in range(len(X_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         0\n",
      "         0.0       0.88      0.93      0.90      1765\n",
      "         1.0       0.15      0.06      0.09       235\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.34      0.33      0.33      2000\n",
      "weighted avg       0.80      0.82      0.81      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
