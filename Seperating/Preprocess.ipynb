{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "def separate_files(df, output_folder):\n",
    "    # Convert 'post_time' column to datetime\n",
    "    df['post_time'] = pd.to_datetime(df['post_time'])\n",
    "\n",
    "    # Sort DataFrame by 'post_time'\n",
    "    df = df.sort_values(by='post_time')\n",
    "\n",
    "    # Remove rows where 'content' column is NaN\n",
    "    df = df.dropna(subset=['content'])\n",
    "\n",
    "    # Define the start date and end date\n",
    "    start_date = df['post_time'].min()\n",
    "    end_date = df['post_time'].max()\n",
    "\n",
    "    folder_count = 1\n",
    "    result = []\n",
    "\n",
    "    while start_date < end_date:\n",
    "        # Define the end date for the training period (four months)\n",
    "        train_end_date = start_date + pd.DateOffset(months=4) - timedelta(days=3)\n",
    "        # Define the start and end dates for the test period (one month)\n",
    "        test_start_date = train_end_date + timedelta(days=1)\n",
    "        test_end_date = test_start_date + pd.DateOffset(months=1) - timedelta(days=1)\n",
    "\n",
    "        # Get the data for the current period\n",
    "        train_data = df[(df['post_time'] >= start_date) & (df['post_time'] <= train_end_date)]\n",
    "        test_data = df[(df['post_time'] >= test_start_date) & (df['post_time'] <= test_end_date)]\n",
    "\n",
    "        # Get the unique ids for the training and test data\n",
    "        train_unique_ids = len(train_data['id'].unique())\n",
    "        test_unique_ids = len(test_data['id'].unique())\n",
    "\n",
    "        # Format the file names\n",
    "        train_period_str = start_date.strftime('%Y%m')\n",
    "        train_file = f\"{train_period_str}.csv\"\n",
    "        test_period_str = test_start_date.strftime('%Y%m')\n",
    "        test_file = f\"{test_period_str}test.csv\"\n",
    "\n",
    "        # Create folder if it doesn't exist\n",
    "        folder_path = os.path.join(output_folder, f\"Folder {folder_count}\")\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        # Write data to CSV files\n",
    "        train_file_path = os.path.join(folder_path, train_file)\n",
    "        test_file_path = os.path.join(folder_path, test_file)\n",
    "        train_data.to_csv(train_file_path, index=False)\n",
    "        test_data.to_csv(test_file_path, index=False)\n",
    "\n",
    "        # Append the statistics to the result list\n",
    "        result.append({\n",
    "            'Folder': folder_count,\n",
    "            'Train File': train_file,\n",
    "            'Train Unique IDs': train_unique_ids,\n",
    "            'Test File': test_file,\n",
    "            'Test Unique IDs': test_unique_ids\n",
    "        })\n",
    "\n",
    "        # Move to the next month\n",
    "        start_date = start_date + pd.DateOffset(months=1)\n",
    "        folder_count += 1\n",
    "\n",
    "    # Convert the result list to a DataFrame\n",
    "    result_df = pd.DataFrame(result)\n",
    "\n",
    "    # Save the result as a CSV file\n",
    "    result_file_path = os.path.join(output_folder, 'separation_result.csv')\n",
    "    result_df.to_csv(result_file_path, index=False)\n",
    "\n",
    "# Specify the input file path\n",
    "input_file_path = r\"C:\\Users\\bradl\\Desktop\\BDA Mid\\bda-midterm\\dataset\\disc_df.csv\"\n",
    "# Specify the output folder\n",
    "output_folder = r\"C:\\Users\\bradl\\Desktop\\BDA Mid\\bda-midterm\\output\"\n",
    "\n",
    "# Read the CSV file\n",
    "disc_df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Call the function to separate the files\n",
    "separate_files(disc_df, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
